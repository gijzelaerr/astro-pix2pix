{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://www.tensorflow.org/alpha/tutorials/generative/pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import roll as _roll\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/scratch/datasets/astro_deconv_2019/\")\n",
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_SIZE = 256\n",
    "OUTPUT_CHANNELS = 1\n",
    "LAMBDA = 100\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFs(img):\n",
    "    axes = tuple(range(img.ndim))\n",
    "    shift = [dim // 2 for dim in img.shape]\n",
    "    return _roll(img, shift, axes)\n",
    "\n",
    "def myiFs(img):\n",
    "    axes = tuple(range(img.ndim))\n",
    "    shift = [-(int(dim) // 2) for dim in img.shape]\n",
    "    return _roll(img, shift, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landman_convolve(arr1, arr2):\n",
    "    \"\"\"\n",
    "    If unequal size arr2 should be the bigger one\n",
    "    \"\"\"\n",
    "    # dim 2> probably crashes kernel\n",
    "    assert(arr1.ndim == 2)\n",
    "    assert(arr2.ndim == 2)\n",
    "    assert arr1.shape == (256, 256)\n",
    "    assert arr2.shape == (256, 256)\n",
    "    arr1hat = tf.signal.rfft2d(myiFs(tf.squeeze(arr1)))\n",
    "    arr2hat = tf.signal.rfft2d(myiFs(tf.squeeze(arr2)))\n",
    "    return myFs(tf.signal.irfft2d(tf.multiply(arr1hat, arr2hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landman_convolve_bigpsf(arr1, big_psf):\n",
    "    assert arr1.shape == (256, 256)\n",
    "    assert big_psf.shape == (512, 512)\n",
    "\n",
    "    #pad = tf.cast((arr2.shape[1] - arr1.shape[1]) // 2, tf.int32)\n",
    "    pad = 128\n",
    "    paddings = tf.constant([[pad, pad], [pad, pad]])\n",
    "    arr1 = tf.pad(tf.squeeze(arr1), paddings, \"CONSTANT\")\n",
    "\n",
    "    arr1hat = tf.signal.rfft2d(myiFs(tf.squeeze(arr1)))\n",
    "    arr2hat = tf.signal.rfft2d(myiFs(tf.squeeze(big_psf)))\n",
    "\n",
    "    return myFs(tf.signal.irfft2d(tf.multiply(arr1hat, arr2hat)))[pad:-pad, pad:-pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_open(path):\n",
    "    content = fits.open(str(path))[0].data.squeeze().astype(np.float32)\n",
    "    if IMG_SIZE == 128:\n",
    "        return content[IMG_SIZE//2:-(IMG_SIZE//2), IMG_SIZE//2:-(IMG_SIZE//2)]\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fits(fits_file):\n",
    "    def internal(data):\n",
    "        return fits.open(BytesIO(data))[0].data.squeeze().astype(np.float32)[..., np.newaxis]\n",
    "    blob = tf.io.read_file(fits_file)\n",
    "    return tf.py_func(internal, [blob], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(glob):\n",
    "    ds = tf.data.Dataset.list_files(str(glob), shuffle=False)\n",
    "    ds = ds.map(load_fits)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(first, *others):\n",
    "    \"\"\"accepts a list of images, normalized to [-.8, .8] relative to the first image\"\"\"\n",
    "    min_ = tf.reduce_min(first)\n",
    "    max_ = tf.reduce_max(first)\n",
    "    f = lambda i: ((i - min_) / ((max_ - min_)/1.6)) - 0.8\n",
    "    return [min_, max_, f(first)] + list(map(f, others))\n",
    "\n",
    "def denormalize(images, min_, max_):\n",
    "    \"\"\"scales image back to min_, max_ range\"\"\"\n",
    "    return [((i + 0.8)/1.6 * (max_ - min_)) + min_ for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_jitter(*images):\n",
    "    if (tf.random.uniform(shape=()) > tf.to_float(0.5))  is not None:\n",
    "        return [tf.image.flip_left_right(i) for i in images]\n",
    "    else:\n",
    "        return list(images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    #https://stackoverflow.com/questions/37092037/tensorflow-what-does-tf-nn-separable-conv2d-do\n",
    "    \n",
    "    #type_ = tf.keras.layers.DepthwiseConv2D\n",
    "    type_ = tf.keras.layers.Conv2D\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(type_(filters,\n",
    "                     size,\n",
    "                     strides=2,\n",
    "                     padding='same',\n",
    "                     kernel_initializer=initializer,\n",
    "                     use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "          result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    if IMG_SIZE == 256:\n",
    "        down_stack_start = [\n",
    "            downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "            downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        ]\n",
    "    elif IMG_SIZE == 128:\n",
    "        down_stack_start = [\n",
    "            downsample(128, 4, apply_batchnorm=False), # (bs, 64, 64, 128)\n",
    "        ]\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "    down_stack = down_stack_start + [\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "    ]\n",
    "\n",
    "    if IMG_SIZE == 256:        \n",
    "        up_stack.append(upsample(64, 4)) # (bs, 128, 128, 128)\n",
    "    elif IMG_SIZE == 128:\n",
    "        # do nothing\n",
    "        ...\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                           strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=[None,None,1])\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[None, None, 1], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[None, None, 1], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "    return total_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(convolved, convolver):\n",
    "    return landman_convolve(tf.squeeze(convolved), tf.squeeze(convolver))\n",
    "    #kernel = tf.squeeze(convolver)[:, :, tf.newaxis, tf.newaxis]\n",
    "    #return tf.nn.conv2d(convolved, kernel, [1, 1, 1, 1], \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def like_loss(predicted, target, bigpsf):\n",
    "    convolved = landman_convolve_bigpsf(tf.squeeze(predicted), tf.squeeze(bigpsf))\n",
    "    #return tf.reduce_sum(tf.multiply(predicted, convolved - 2 * target)) \n",
    "    return tf.reduce_sum(tf.tensordot(tf.squeeze(predicted), (tf.squeeze(convolved) - 2 * tf.squeeze(target)), axes=1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_loss(predicted, target, clean_beam):\n",
    "    return l1(convolve(predicted, clean_beam), convolve(target, clean_beam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(f, a, imgdata, title):\n",
    "    i = a.pcolor(imgdata, cmap='cubehelix')\n",
    "    f.colorbar(i, ax=a)\n",
    "    a.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(prediction, input_, target):\n",
    "    f, ((a1, a2, a3)) = plt.subplots(1, 3, figsize=(15,3))\n",
    "    render(f, a1, tf.squeeze(input_), 'input_')\n",
    "    render(f, a2, tf.squeeze(target), 'target')\n",
    "    render(f, a3, tf.squeeze(prediction), 'prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        predicted = generator(input_image, training=True)\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, predicted], training=True)\n",
    "        gen_loss = generator_loss(disc_generated_output, predicted, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_likelyhood(input_image, target, bigpsf):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        predicted = generator(input_image, training=True)\n",
    "        likelyhood_loss = like_loss(predicted, target, bigpsf) / 2e8 + 1\n",
    "        l1_loss = tf.reduce_mean(tf.abs(target - predicted))\n",
    "        total_loss = likelyhood_loss + l1_loss  # * LAMBDA\n",
    "\n",
    "    print(float(likelyhood_loss), float(l1_loss))\n",
    "    \n",
    "    generator_gradients = gen_tape.gradient(total_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(a, b):\n",
    "    return tf.math.reduce_sum(tf.math.abs(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "def train(train_dataset, test_dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        step = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for input_, target, psf, clean_beam in train_dataset:\n",
    "            min_, max_, input_, target, = normalize(input_, target)\n",
    "            \n",
    "            #train_step(input_, target)\n",
    "            train_step_likelyhood(input_, target, psf)\n",
    "            \n",
    "            step += 1\n",
    "\n",
    "            test_interval = 100\n",
    "            if (step + 1) % test_interval == 0:\n",
    "                clear_output(wait=True)\n",
    "                for test_input, test_target, test_psf, clean_beam, wsclean in test_dataset.take(1):\n",
    "                \n",
    "                    r = normalize(test_input, test_target, clean_beam, wsclean)\n",
    "                    min_, max_, test_input, test_target, clean_beam, wsclean = r\n",
    "\n",
    "                    # the training=True is intentional here since\n",
    "                    # we want the batch statistics while running the model\n",
    "                    # on the test dataset. If we use training=False, we will get\n",
    "                    # the accumulated statistics learned from the training dataset\n",
    "                    # (which we don't want)\n",
    "                    prediction = generator(test_input, training=True)\n",
    "                    \n",
    "                    likelyhood_loss = like_loss(prediction, test_target, test_psf)\n",
    "                    l1_loss = tf.reduce_mean(tf.abs(target - prediction))\n",
    "\n",
    "                    generate_images(prediction, test_input, test_target)\n",
    "                    clean_sky = convolve(target, clean_beam)\n",
    "                    vacuum_l1 = l1(convolve(prediction, clean_beam), clean_sky)\n",
    "                    wsclean_l1 = l1(convolve(wsclean, clean_beam),clean_sky )\n",
    "                    scores.append(vacuum_l1)\n",
    "                    print(f\"l1 vacuum: {vacuum_l1.numpy()} wsclean: {wsclean_l1.numpy()}\")\n",
    "\n",
    "                    duration = time.time()-start\n",
    "                    speed = step / duration\n",
    "                    print(f\"step: {step + 1} epoch: {epoch + 1} duration: {duration:.2f}s step/s: {speed:.2f}\\n\")\n",
    "                    #for i in scores:\n",
    "                    #    print(i)\n",
    "\n",
    "        # saving (checkpoint) the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirty_dataset = make_dataset(PATH / 'train/*-dirty.fits')\n",
    "train_skymodel_dataset = make_dataset(PATH / 'train/*-skymodel.fits')\n",
    "train_psf_dataset = make_dataset(PATH / 'train/*-psf.fits')\n",
    "train_clean_beam_dataset = make_dataset(PATH / 'train/*-clean-beam.fits')\n",
    "train_dataset = tf.data.Dataset.zip((train_dirty_dataset, train_skymodel_dataset, train_psf_dataset, train_clean_beam_dataset))\n",
    "train_dataset = train_dataset.map(random_jitter)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(1)\n",
    "\n",
    "test_dirty_dataset = make_dataset(PATH / 'test/*-dirty.fits')\n",
    "test_wsclean_dataset = make_dataset(PATH / 'test/*-wsclean-model.fits')\n",
    "test_skymodel_dataset = make_dataset(PATH / 'test/*-skymodel.fits')\n",
    "test_psf_dataset = make_dataset(PATH / 'test/*-psf.fits')\n",
    "test_clean_beam_dataset = make_dataset(PATH / 'test/*-clean-beam.fits')\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((test_dirty_dataset, test_skymodel_dataset, test_psf_dataset, test_clean_beam_dataset, test_wsclean_dataset))\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5)  # 2e-4\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=2e-4, beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-7493e808d350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-821bd7b31474>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, test_dataset, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigpsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_beam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mmin_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "train(train_dataset, test_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manual trying out shit space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckpointLoadStatus = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_target, psf, clean_beam, wsclean = list(test_dataset.take(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = tf.squeeze(psf)[:, :, tf.newaxis, tf.newaxis]\n",
    "convolved = tf.nn.conv2d(test_target, filter_, [1, 1, 1, 1], \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_, max_, i_n = normalize(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = denormalize([generator(i_n)], min_, max_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanbeam_sky = convolve(test_target, clean_beam)\n",
    "cleanbeam_prediction = convolve(prediction, clean_beam)\n",
    "cleanbeam_prediction_landman = landman_convolve(tf.squeeze(prediction), tf.squeeze(clean_beam))\n",
    "cleanbeam_wsclean = convolve(wsclean, clean_beam)\n",
    "vacuum_l1 = l1(cleanbeam_prediction, cleanbeam_sky)\n",
    "wsclean_l1 = l1(cleanbeam_wsclean, cleanbeam_sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((a1, a2), (a3, a4), (a5, a6)) = plt.subplots(3, 2, figsize=(14,16))\n",
    "render(a1, tf.squeeze(test_input), 'test_input')\n",
    "render(a2, tf.squeeze(test_target), 'test_target')\n",
    "render(a3, tf.squeeze(cleanbeam_prediction_landman), 'cleanbeam_prediction_landman')\n",
    "render(a4, tf.squeeze(cleanbeam_prediction), 'cleanbeam_prediction')\n",
    "render(a5, tf.squeeze(cleanbeam_sky), 'cleanbeam_sky')\n",
    "render(a6, tf.squeeze(cleanbeam_wsclean), 'cleanbeam_wsclean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = landman_convolve(tf.squeeze(prediction), tf.squeeze(psf))\n",
    "b = landman_convolve_bigpsf(tf.squeeze(prediction), tf.squeeze(big_psf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((a1, a2)) = plt.subplots(1, 2, figsize=(12,4))\n",
    "vmin = min(a.numpy().min(), b.numpy().min())\n",
    "vmax = max(a.numpy().max(), b.numpy().max())\n",
    "i1 = a1.pcolor(tf.squeeze(a), cmap='cubehelix') #, vmin=vmin, vmax=vmax)\n",
    "f.colorbar(i1, ax=a1)\n",
    "a1.set_title('prediction convolved with psf 256px')\n",
    "i2 = a2.pcolor(tf.squeeze(b), cmap='cubehelix') #, vmin=vmin, vmax=vmax)\n",
    "f.colorbar(i2, ax=a2)\n",
    "_ = a2.set_title('prediction convolved with psf 512px')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
