{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2385f765fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/gijs/Work/astro-pix2pix/.venv3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5466\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     raise ValueError(\n\u001b[0;32m-> 5468\u001b[0;31m         \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5470\u001b[0m   \u001b[0;31m# Monkey patch to get rid of an unnecessary conditional since the context is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEPARABLE_CONV = False   # use separable convolutions in the generator\n",
    "NGF = 64  # number of generator filters in first conv layer\n",
    "DATASET_PATH = \"/scratch/datasets/kat7_2000/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_ = (\"psf\", \"dirty\", \"skymodel\", \"image\", \"model\")\n",
    "fits_open = lambda x: fits.open(str(x))[0].data.squeeze()\n",
    "def dataset_generator(path=DATASET_PATH):\n",
    "    p = Path(path)\n",
    "    sorted_ = zip(*(sorted(p.glob(f\"*-{t}.fits\")) for t in types_))\n",
    "    for i in sorted_:\n",
    "        yield tuple(fits_open(j)[:,:,np.newaxis] for j in i) # we nee to add 1 channel\n",
    "        #yield tuple(fits_open(j)for j in i) # we nee to add 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(dataset_generator, output_types=(tf.float32,) * 5)\n",
    "ds = ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = ds.make_one_shot_iterator()\n",
    "psf, dirty, skymodel, image, model = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_conv(batch_input, out_channels):\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    if SEPARABLE_CONV:\n",
    "        return tf.layers.separable_conv2d(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\",\n",
    "                                          depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "    else:\n",
    "        return tf.layers.conv2d(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\",\n",
    "                                kernel_initializer=initializer)\n",
    "\n",
    "\n",
    "def gen_deconv(batch_input, out_channels):\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    if SEPARABLE_CONV:\n",
    "        _b, h, w, _c = batch_input.shape\n",
    "        resized_input = tf.image.resize_images(batch_input, [h * 2, w * 2],\n",
    "                                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        return tf.layers.separable_conv2d(resized_input, out_channels, kernel_size=4, strides=(1, 1), padding=\"same\",\n",
    "                                          depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "    else:\n",
    "        return tf.layers.conv2d_transpose(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\",\n",
    "                                          kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, a):\n",
    "    with tf.name_scope(\"lrelu\"):\n",
    "        # adding these together creates the leak part and linear part\n",
    "        # then cancels them out by subtracting/adding an absolute value term\n",
    "        # leak: a*x/2 - a*abs(x)/2\n",
    "        # linear: x/2 + abs(x)/2\n",
    "\n",
    "        # this block looks like it has 2 inputs on the graph unless we do this\n",
    "        x = tf.identity(x)\n",
    "        return (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(generator_inputs, generator_outputs_channels):\n",
    "    layers = []\n",
    "\n",
    "    # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
    "    with tf.variable_scope(\"encoder_1\"):\n",
    "        output = gen_conv(generator_inputs, NGF)\n",
    "        layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        NGF * 2, # encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]\n",
    "        NGF * 4, # encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]\n",
    "        NGF * 8, # encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]\n",
    "        NGF * 8, # encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]\n",
    "        NGF * 8, # encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]\n",
    "        NGF * 8, # encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]\n",
    "        NGF * 8, # encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]\n",
    "    ]\n",
    "\n",
    "    for out_channels in layer_specs:\n",
    "        with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "            rectified = lrelu(layers[-1], 0.2)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "            convolved = gen_conv(rectified, out_channels)\n",
    "            output = batchnorm(convolved)\n",
    "            layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        (NGF * 8, 0.5),   # decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]\n",
    "        (NGF * 8, 0.5),   # decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]\n",
    "        (NGF * 8, 0.5),   # decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]\n",
    "        (NGF * 8, 0.0),   # decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]\n",
    "        (NGF * 4, 0.0),   # decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]\n",
    "        (NGF * 2, 0.0),   # decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]\n",
    "        (NGF, 0.0),       # decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]\n",
    "    ]\n",
    "\n",
    "    num_encoder_layers = len(layers)\n",
    "    for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
    "        skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "        with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "            if decoder_layer == 0:\n",
    "                # first decoder layer doesn't have skip connections\n",
    "                # since it is directly connected to the skip_layer\n",
    "                input = layers[-1]\n",
    "            else:\n",
    "                input = tf.concat([layers[-1], layers[skip_layer]], axis=3)\n",
    "\n",
    "            rectified = tf.nn.relu(input)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
    "            output = gen_deconv(rectified, out_channels)\n",
    "            output = batchnorm(output)\n",
    "\n",
    "            if dropout > 0.0:\n",
    "                output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "            layers.append(output)\n",
    "\n",
    "    # decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]\n",
    "    with tf.variable_scope(\"decoder_1\"):\n",
    "        input = tf.concat([layers[-1], layers[0]], axis=3)\n",
    "        rectified = tf.nn.relu(input)\n",
    "        output = gen_deconv(rectified, generator_outputs_channels)\n",
    "        output = tf.tanh(output)\n",
    "        layers.append(output)\n",
    "\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm(inputs):\n",
    "    return tf.layers.batch_normalization(inputs, axis=3, epsilon=1e-5, momentum=0.1, training=True,\n",
    "                                         gamma_initializer=tf.random_normal_initializer(1.0, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"generator\"):\n",
    "    out_channels = 1\n",
    "    outputs = create_generator(dirty, out_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
