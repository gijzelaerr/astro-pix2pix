{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vacuum.model import create_model\n",
    "from vacuum.io import load_data, preprocess, deprocess, fits_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/scratch/datasets/kat7_2000/\"\n",
    "\n",
    "SEPARABLE_CONV = False   # use separable convolutions in the generator\n",
    "NGF = 64                 # number of generator filters in first conv layer\n",
    "NDF = 64                 # number of discriminator filters in first conv laye\n",
    "BATCH_SIZE = 5           # number of images in batch\n",
    "CROP_SIZE = 256\n",
    "EPS = 1e-12\n",
    "FLIP = False              # flip images horizontally during training\n",
    "SCALE_SIZE = 256         # scale images to this size before cropping to 256x256\n",
    "MAX_EPOCHS = 1           # number of training epochs\n",
    "LR = 0.0002              # initial learning rate for adam\n",
    "BETA1 = 0.5              # momentum term of adam\n",
    "L1_WEIGHT = 100.0        # weight on L1 term for generator gradient\n",
    "GAN_WEIGHT = 1.0         # weight on GAN term for generator gradient\n",
    "INPUT_MULTIPLY = 1.0     # Use this to scale in the max input fluxes to about 5 Jy \n",
    "DATA_START = 1840\n",
    "DATA_END = 1899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples count = 59\n"
     ]
    }
   ],
   "source": [
    "batch, count = load_data(INPUT_DIR, CROP_SIZE, FLIP, SCALE_SIZE, MAX_EPOCHS,\n",
    "                         BATCH_SIZE, start=DATA_START, end=DATA_END)\n",
    "steps_per_epoch = int(math.ceil(count / BATCH_SIZE))\n",
    "iter = batch.make_one_shot_iterator()\n",
    "index, min_flux, max_flux, psf, dirty, skymodel = iter.get_next()\n",
    "print(\"examples count = %d\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_dirty = preprocess(dirty, min_, max_)\n",
    "scaled_skymodel = preprocess(skymodel, min_, max_)\n",
    "scaled_psf = preprocess(psf, min_, max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprocessed_dirty = deprocess(scaled_dirty, min_, max_)\n",
    "deprocessed_skymodel = deprocess(scaled_skymodel, min_, max_)\n",
    "deprocessed_psf = deprocess(scaled_psf, min_, max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=644, shape=(5,), dtype=float32, numpy=\n",
       " array([2.3067167, 1.6453992, 1.3210348, 1.47137  , 1.7186923],\n",
       "       dtype=float32)>, <tf.Tensor: id=646, shape=(5,), dtype=float32, numpy=\n",
       " array([2.3067167, 1.6453991, 1.3210349, 1.47137  , 1.7186924],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(dirty, axis=(1, 2, 3)),  tf.reduce_max(deprocessed_dirty, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = tf.reduce_min(dirty, axis=(1, 2, 3))\n",
    "max_ = tf.reduce_max(dirty, axis=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=335, shape=(5,), dtype=float32, numpy=\n",
       " array([2.3067167, 1.6453992, 1.3210348, 1.47137  , 1.7186923],\n",
       "       dtype=float32)>, <tf.Tensor: id=353, shape=(5,), dtype=float32, numpy=\n",
       " array([2.3067167, 1.6453992, 1.3210348, 1.47137  , 1.7186923],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_flux, max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=167, shape=(5,), dtype=float32, numpy=array([2.34, 1.61, 1.17, 1.4 , 1.69], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dirty / max_[:, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.numpy()[4].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(a, imgdata, title):\n",
    "    i = a.pcolor(imgdata, cmap='cubehelix')\n",
    "    f.colorbar(i, ax=a)\n",
    "    a.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(i, x=0, y=0):\n",
    "    return tf.image.pad_to_bounding_box(\n",
    "        i,\n",
    "        max(0, y),\n",
    "        max(0, x),\n",
    "        i.shape.as_list()[1] + abs(y),\n",
    "        i.shape.as_list()[2] + abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_convolve(skymodel, psf, y, x):\n",
    "    shifted = shift(psf, y=y, x=x)\n",
    "    #filter_ = tf.expand_dims(tf.expand_dims(tf.squeeze(shifted), 2), 3)\n",
    "    convolved = tf.nn.conv2d(skymodel, shifted, [1, 1, 1, 1], \"SAME\")\n",
    "    residual = deprocessed_dirty - convolved\n",
    "    return convolved, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "input depth must be evenly divisible by filter depth: 5 vs 257 [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-71abb266dd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshifted_convolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprocessed_skymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprocessed_psf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'descaled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprocessed_dirty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprocessed_dirty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvolved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'convolved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fdbd5b128d5e>\u001b[0m in \u001b[0;36mshifted_convolve\u001b[0;34m(skymodel, psf, y, x)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mshifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#filter_ = tf.expand_dims(tf.expand_dims(tf.squeeze(shifted), 2), 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconvolved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprocessed_dirty\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mconvolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/vacuum-cleaner/.venv3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/vacuum-cleaner/.venv3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input depth must be evenly divisible by filter depth: 5 vs 257 [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "convolved, residual = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=-1, x=-1)\n",
    "f, ((a1, a2), (a3, a4)) = plt.subplots(2, 2, figsize=(16,14))\n",
    "render(a1, descaled.numpy().squeeze(), 'descaled')\n",
    "render(a2, deprocessed_dirty.numpy().squeeze(), 'deprocessed_dirty')\n",
    "render(a3, convolved.numpy().squeeze(), 'convolved')\n",
    "#render(a4, psf.numpy().squeeze(), 'psf')\n",
    "render(a4, residual.numpy().squeeze(), 'residual')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making sure the shift is sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, residual1 = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=-1, x=-1)\n",
    "_, residual2 = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=1, x=1)\n",
    "_, residual3 = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=0, x=0)\n",
    "_, residual4 = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=-1, x=1)\n",
    "_, residual5 = shifted_convolve(deprocessed_skymodel, deprocessed_psf, y=1, x=-1)\n",
    "f, ((a1, a2), (a3, a4), (a5, a6)) = plt.subplots(3, 2, figsize=(16,14))\n",
    "render(a1, residual1.numpy().squeeze(), 'residual1')\n",
    "render(a2, residual2.numpy().squeeze(), 'residual2')\n",
    "render(a3, residual3.numpy().squeeze(), 'residual3')\n",
    "render(a4, residual4.numpy().squeeze(), 'residual4')\n",
    "render(a5, residual5.numpy().squeeze(), 'residual5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
